# Use multi-stage build with caching optimizations
FROM nvidia/cuda:12.8.1-cudnn-devel-ubuntu24.04 AS base

# Set environment variables to avoid interactive prompts during build
ENV DEBIAN_FRONTEND=noninteractive
ENV PYTHONUNBUFFERED=1
ENV HF_HOME=/WAN/huggingface

# Install essential packages, including from the reference Dockerfile for better compatibility
# Corrected libgl1-mesa-glx to libgl1 for Ubuntu 24.04 compatibility
# Added ffmpeg for video processing
RUN apt-get update && apt-get install -y --no-install-recommends \
    git \
    git-lfs \
    wget \
    aria2 \
    unzip \
    ffmpeg \
    build-essential \
    libgl1 \
    libglib2.0-0 \
    software-properties-common \
    dos2unix \
    && add-apt-repository ppa:deadsnakes/ppa \
    && apt-get update \
    && apt-get install -y python3.12 python3.12-venv python3-pip \
    && rm -rf /var/lib/apt/lists/*

# Set python3.12 as default
RUN ln -sf /usr/bin/python3.12 /usr/bin/python
RUN ln -sf /usr/bin/python3.12 /usr/bin/python3

# Create virtual environment and set PATH to use it
RUN python3.12 -m venv /venv
ENV PATH="/venv/bin:$PATH"
ENV VIRTUAL_ENV="/venv"

# Set working directory
WORKDIR /

# Clone the ComfyUI repository
RUN git clone https://github.com/comfyanonymous/ComfyUI.git

# Verify we're using the virtual environment and install/upgrade Python build tools
RUN which python && which pip && \
    pip install --no-cache-dir --upgrade pip setuptools wheel packaging

# Install Python dependencies for ComfyUI using the virtual environment
RUN pip install --no-cache-dir --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu128

# Install other dependencies.
RUN pip install --no-cache-dir triton
RUN pip install --no-cache-dir https://huggingface.co/Kijai/PrecompiledWheels/resolve/main/sageattention-2.1.0-cp312-cp312-linux_x86_64.whl
RUN pip install --no-cache-dir invisible-watermark onnx onnxruntime opencv-python

# Install dependencies found in the error logs
RUN pip install --no-cache-dir opencv-python-headless accelerate

# Install packages from ComfyUI's requirements file
RUN pip install --no-cache-dir -r /ComfyUI/requirements.txt

# --- Custom Nodes Installation ---
WORKDIR /ComfyUI/custom_nodes
RUN git clone https://github.com/Comfy-Org/ComfyUI-Manager.git
RUN git clone https://github.com/kijai/ComfyUI-WanVideoWrapper.git
RUN git clone https://github.com/kijai/ComfyUI-KJNodes.git
RUN git clone https://github.com/Kosinkadink/ComfyUI-VideoHelperSuite.git
RUN git clone https://github.com/rgthree/rgthree-comfy.git
RUN git clone https://github.com/kijai/ComfyUI-DepthAnythingV2.git
RUN git clone https://github.com/M1kep/ComfyLiterals.git
RUN git clone https://github.com/Maxed-Out-99/ComfyUI-MaxedOut.git
RUN git clone https://github.com/ltdrdata/ComfyUI-Impact-Pack.git
RUN git clone https://github.com/ltdrdata/ComfyUI-Impact-Subpack.git
RUN git clone --recursive https://github.com/ssitu/ComfyUI_UltimateSDUpscale.git
RUN git clone https://github.com/pythongosssss/ComfyUI-Custom-Scripts.git
RUN git clone https://github.com/city96/ComfyUI-GGUF.git
RUN git clone https://github.com/lldacing/ComfyUI_PuLID_Flux_ll.git
RUN git clone https://github.com/crystian/ComfyUI-Crystools.git
RUN git clone https://codeberg.org/Gourieff/comfyui-reactor-node.git
RUN git clone https://github.com/kijai/ComfyUI-Florence2.git
RUN git clone https://github.com/safzanpirani/flux-kontext-diff-merge.git
RUN git clone https://github.com/ClownsharkBatwing/RES4LYF.git

# Loop through custom nodes and install their requirements using virtual environment
RUN for d in /ComfyUI/custom_nodes/*/; do \
    if [ -f "$d/requirements.txt" ]; then \
    pip install --no-cache-dir -r "$d/requirements.txt"; \
    fi; \
    done

# --- End Custom Nodes ---

# Set back to the main ComfyUI directory
WORKDIR /ComfyUI



# Create the extra_model_paths.yaml to map the volume paths
# Corrected top-level key to 'comfyui' and 'unclip_models' to 'text_encoders'
RUN echo 'comfyui:' > /extra_model_paths.yaml && \
    echo '  base_path: /WAN' >> /extra_model_paths.yaml && \
    echo '  diffusion_models: models/diffusion_models' >> /extra_model_paths.yaml && \
    echo '  vae: models/vae' >> /extra_model_paths.yaml && \
    echo '  loras: models/loras' >> /extra_model_paths.yaml && \
    echo '  clip_vision: models/clip_vision' >> /extra_model_paths.yaml && \
    echo '  clip: models/clip' >> /extra_model_paths.yaml && \
    echo '  unet: models/unet' >> /extra_model_paths.yaml && \
    echo '  text_encoders: models/text_encoders' >> /extra_model_paths.yaml

# Create the startup script that downloads models on-demand
# This script is executed every time the pod starts
COPY --chown=root:root <<'EOF' /start.sh
#!/bin/bash
set -ex

# Virtual environment is already in PATH, but activate it explicitly for clarity
source /venv/bin/activate

echo "--- Starting RunPod container ---"

# Define directories within the /WAN volume
DIFFUSION_MODELS_DIR="/WAN/models/diffusion_models"
VAE_DIR="/WAN/models/vae"
LORAS_DIR="/WAN/models/loras"
TEXT_ENCODERS_DIR="/WAN/models/text_encoders"
CLIP_DIR="/WAN/models/clip"
CLIP_VISION_DIR="/WAN/models/clip_vision"
UNET_DIR="/WAN/models/unet"

# Create directories if they don't exist
echo "--- Creating model directories ---"
mkdir -p "$DIFFUSION_MODELS_DIR" "$VAE_DIR" "$LORAS_DIR" "$TEXT_ENCODERS_DIR" "$CLIP_VISION_DIR" "$UNET_DIR" "$CLIP_DIR"

# --- Model Download Section ---
# For each model, check if the file exists. If not, download it.
echo "--- Checking for models ---"

# Main Model
if [ ! -f "$UNET_DIR/flux1-kontext-dev-Q8_0.gguf" ]; then
    echo "Downloading FLUX.1-Kontext model..."
    aria2c -x 16 -s 16 -k 1M -d "$UNET_DIR" -o "flux1-kontext-dev-Q8_0.gguf" "https://huggingface.co/unsloth/FLUX.1-Kontext-dev-GGUF/resolve/main/flux1-kontext-dev-Q8_0.gguf"
else
    echo "FLUX.1-Kontext model already exists."
fi

# Text Encoder Model 
if [ ! -f "$TEXT_ENCODERS_DIR/t5xxl_fp16.safetensors" ]; then
    echo "Downloading T5 text encoder model..."
    aria2c -x 16 -s 16 -k 1M -d "$TEXT_ENCODERS_DIR" -o "t5xxl_fp16.safetensors" "https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/t5xxl_fp16.safetensors"
else
    echo "T5 text encoder model already exists."
fi

# CLIP Model
if [ ! -f "$CLIP_DIR/ViT-L-14-BEST-smooth-GmP-TE-only-HF-format.safetensors" ]; then
    echo "Downloading CLIP model..."
    aria2c -x 16 -s 16 -k 1M -d "$CLIP_DIR" -o "ViT-L-14-BEST-smooth-GmP-TE-only-HF-format.safetensors" "https://huggingface.co/zer0int/CLIP-GmP-ViT-L-14/resolve/main/ViT-L-14-BEST-smooth-GmP-TE-only-HF-format.safetensors"
else
    echo "CLIP model already exists."
fi

# CLIP Text Model
if [ ! -f "$CLIP_DIR/ViT-L-14-TEXT-detail-improved-hiT-GmP-TE-only-HF.safetensors" ]; then
    echo "Downloading CLIP text model..."
    aria2c -x 16 -s 16 -k 1M -d "$CLIP_DIR" -o "ViT-L-14-TEXT-detail-improved-hiT-GmP-TE-only-HF.safetensors" "https://huggingface.co/zer0int/CLIP-GmP-ViT-L-14/resolve/main/ViT-L-14-TEXT-detail-improved-hiT-GmP-TE-only-HF.safetensors"
else
    echo "CLIP text model already exists."
fi

# VAE Model
if [ ! -f "$VAE_DIR/ae.safetensors" ]; then
    echo "Downloading VAE model..."
    aria2c -x 16 -s 16 -k 1M -d "$VAE_DIR" -o "ae.safetensors" "https://huggingface.co/Comfy-Org/Lumina_Image_2.0_Repackaged/resolve/main/split_files/vae/ae.safetensors"
else
    echo "VAE model already exists."
fi

echo "All models checked. Starting ComfyUI..."

# Launch ComfyUI
cd /ComfyUI
python main.py --listen 0.0.0.0 --port 8189 --extra-model-paths-config /extra_model_paths.yaml
EOF

# Expose the default ComfyUI port
EXPOSE 8189

# Fix line endings and ensure the script is executable
RUN dos2unix /start.sh && chmod +x /start.sh

# Set the entrypoint for the container
CMD ["/start.sh"]